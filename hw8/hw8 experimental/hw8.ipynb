{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5876ac12",
      "metadata": {
        "id": "5876ac12"
      },
      "source": [
        "# Homework 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77cf84a1",
      "metadata": {
        "id": "77cf84a1"
      },
      "source": [
        "In this homework, we will explore boosting and investigate how it performs on two datasets with two different weak learnings. First, let us look at the spiral dataset with decision stumps as the weak learning. Then, we will implement and explore the Viola-Jones face detector features as weak classifiers with AdaBoost.\n",
        "\n",
        "There are a number of programming **tasks** and **quiz questions** in this homework.\n",
        "- For **tasks**, you will need to either **add code between comments \"`#### TASK N CODE`\"** to complete them or **modify code between those comments**. **DO NOT delete the comments \"#### TASK N CODE\". This is for graders' reference and you might not get full points if you tamper with these comments.**\n",
        "- For **quiz questions**, you will need to answer in a few sentences between the given lines.\n",
        "- For **optional tasks**, you are **NOT required to turn them in**. However, we encourage you to complete them as they are good practice.\n",
        "- For **challenge-optional tasks**, you are **NOT required to turn them in**. However, you will receive extra credit for completing the challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b37471",
      "metadata": {
        "id": "62b37471"
      },
      "source": [
        "## Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b24d47ed",
      "metadata": {
        "id": "b24d47ed"
      },
      "outputs": [],
      "source": [
        "!wget -O $PWD/utils.py https://www.dropbox.com/scl/fi/m3v7lwkxssqo77x5b92zc/utils.py?rlkey=rm9ane55csq5tqga54w394zo8&dl=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3abeb6c-2cc8-4bee-99e6-1b9c1c139edf",
      "metadata": {
        "id": "b3abeb6c-2cc8-4bee-99e6-1b9c1c139edf"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862b739a-28cf-43d0-b5a5-01d875c70cdc",
      "metadata": {
        "id": "862b739a-28cf-43d0-b5a5-01d875c70cdc"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c71b0b",
      "metadata": {
        "id": "04c71b0b"
      },
      "source": [
        "## [Task 1] Implementation of AdaBoost\n",
        "Here, we implement AdaBoost. Add line numbers (`ctrl`+ m + l).\n",
        "1. Implement the distribution update in the `fit` method.\n",
        "2. Implement the `predict` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "149943b7-b22d-4a5e-8282-c9dda58f3a5f",
      "metadata": {
        "id": "149943b7-b22d-4a5e-8282-c9dda58f3a5f"
      },
      "outputs": [],
      "source": [
        "class AdaBoost:\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_learner,\n",
        "        n_learners: int = 50,\n",
        "        sample_size: Optional[int] = None,\n",
        "        **base_learner_kwargs\n",
        "    ):\n",
        "        '''\n",
        "        Boost base_learners for up to n_learners times.\n",
        "\n",
        "        Args:\n",
        "            base_learner: Class of weak learner, must support sample weighting as\n",
        "                .fit(X, y, sample_weight=D) if sample_size is set to None (subsampling\n",
        "                disabled), and .predict(X).\n",
        "            n_learners: (default 50) Maximum number of weak learners to fit.\n",
        "            sample_size: (default None) Number of samples drawn for fitting each weak\n",
        "                leaner. The samples are drawn according to the distribution D^{(t)}\n",
        "                and then fit rather than fitting by weighing samples according to the\n",
        "                distribution. Data is subsampled if not None, else it is weighed.\n",
        "        '''\n",
        "        self.base_learner = base_learner\n",
        "        self.n_learners = n_learners\n",
        "        self.sample_size = sample_size\n",
        "        self.base_learner_kwargs = base_learner_kwargs\n",
        "\n",
        "        self.learned_clfs = []\n",
        "        self.learned_clfs_alphas = []\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        '''\n",
        "        Fits base learners using AdaBoost algorithm.\n",
        "\n",
        "        Args:\n",
        "            X: Data features. shape (m, d)\n",
        "            y: Data labels, must be binary +/-1. shape (m)\n",
        "        '''\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "\n",
        "        self.learned_clfs = []\n",
        "        self.learned_clfs_alphas = []\n",
        "\n",
        "        m = X.shape[0]\n",
        "        D = np.ones(m) / m\n",
        "\n",
        "        for t in range(self.n_learners):\n",
        "            # Instantiate a base learner\n",
        "            clf = self.base_learner(**self.base_learner_kwargs)\n",
        "\n",
        "            # Fit the learner\n",
        "            if self.sample_size is not None:\n",
        "                # Subsample from X and y using weights D\n",
        "                sample_idxs = np.random.choice(m, self.sample_size, replace=True, p=D)\n",
        "                clf.fit(X[sample_idxs], y[sample_idxs])\n",
        "            else:\n",
        "                # Use D as sample_weight when fitting\n",
        "                clf.fit(X, y, sample_weight=D)\n",
        "\n",
        "            # Get coefficient for fitted learner\n",
        "            y_pred = clf.predict(X)\n",
        "            eps_t = utils.empirical_err(y, y_pred, sample_weight=D)\n",
        "\n",
        "            if np.isclose(eps_t, 0.5):\n",
        "                # Adding this classifier does not help\n",
        "                break\n",
        "            elif np.isclose(eps_t, 0.):\n",
        "                # Achieved classifier that fits fully\n",
        "                alpha_t = 1.\n",
        "                self.learned_clfs.append(clf)\n",
        "                self.learned_clfs_alphas.append(alpha_t)\n",
        "                break\n",
        "            else:\n",
        "                alpha_t = (np.log(1 - eps_t) - np.log(eps_t)) / 2\n",
        "\n",
        "            #### TASK 1 CODE\n",
        "            # Update D according to alpha_t\n",
        "            #### TASK 1 CODE\n",
        "\n",
        "            # Record classifier and alpha_t\n",
        "            self.learned_clfs.append(clf)\n",
        "            self.learned_clfs_alphas.append(alpha_t)\n",
        "\n",
        "    def predict(self, X: np.ndarray):\n",
        "        '''\n",
        "        Returns predictions for data.\n",
        "\n",
        "        Args:\n",
        "            X: Data features. shape (n)\n",
        "\n",
        "        Returns:\n",
        "            shape (n), binary vector of +/-1.\n",
        "        '''\n",
        "        assert len(self.learned_clfs) > 0, 'Classifier not trained!'\n",
        "\n",
        "        #### TASK 1 CODE\n",
        "         #### TASK 1 CODE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fca1fde",
      "metadata": {
        "id": "2fca1fde"
      },
      "source": [
        "Now, let us generate spiral data similar to that in the second homework and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48b4f852-4608-45e3-96a0-0205750c08fe",
      "metadata": {
        "id": "48b4f852-4608-45e3-96a0-0205750c08fe"
      },
      "outputs": [],
      "source": [
        "LABELS = [-1, 1]\n",
        "SP_THETA_SIGMA = 0.15\n",
        "SP_R_SIGMA = 0.04\n",
        "\n",
        "m = 5000\n",
        "Xsp, ysp = utils.generate_spiral_data(m, noise_level=0.08, theta_sigma=SP_THETA_SIGMA, r_sigma=SP_R_SIGMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b923ae-5721-4b87-bbdf-02db7d18f045",
      "metadata": {
        "id": "14b923ae-5721-4b87-bbdf-02db7d18f045"
      },
      "outputs": [],
      "source": [
        "def scatter_plot(X, y, **plot_kwargs):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, l in enumerate(LABELS):\n",
        "        l_idxs = np.where(y == l)\n",
        "        plt.scatter(X[l_idxs, 0], X[l_idxs, 1], label=l, c=utils.cmap_fg[i], **plot_kwargs)\n",
        "    plt.xlabel('$x_1$') # matplotlib allows basic latex in rendered text!\n",
        "    plt.ylabel('$x_2$')\n",
        "    plt.legend(title='label')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6854f9e3-4409-4908-adb9-8bcbf6a56727",
      "metadata": {
        "id": "6854f9e3-4409-4908-adb9-8bcbf6a56727"
      },
      "outputs": [],
      "source": [
        "scatter_plot(Xsp, ysp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00147bd6-1400-42ce-95b7-be9444ac0820",
      "metadata": {
        "id": "00147bd6-1400-42ce-95b7-be9444ac0820"
      },
      "outputs": [],
      "source": [
        "train_test_ratio = 0.8\n",
        "Xsp_train, ysp_train, Xsp_test, ysp_test = utils.create_split(Xsp, ysp, train_test_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d8a013a",
      "metadata": {
        "id": "2d8a013a"
      },
      "source": [
        "### Running AdaBoost with Decision Stumps\n",
        "\n",
        "Now, we can play around with how AdaBoost performs on the spiral data when using decision stumps as the weak classifier. Note that there are two different interfaces with which you can use `AdaBoost`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36051318-9166-4f08-bd35-20818d9ca8cb",
      "metadata": {
        "id": "36051318-9166-4f08-bd35-20818d9ca8cb"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# AdaBoost with sample weighting\n",
        "boosted_clf = AdaBoost(DecisionTreeClassifier, n_learners=100, max_depth=1)\n",
        "boosted_clf.fit(Xsp_train, ysp_train)\n",
        "\n",
        "ysp_train_predict = boosted_clf.predict(Xsp_train)\n",
        "train_err = utils.empirical_err(ysp_train, ysp_train_predict)\n",
        "\n",
        "print(f'Train error: {train_err*100:0.2f}%')\n",
        "\n",
        "ysp_test_predict = boosted_clf.predict(Xsp_test)\n",
        "test_err = utils.empirical_err(ysp_test, ysp_test_predict)\n",
        "\n",
        "print(f'Test error: {test_err*100:0.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc79978c-aca2-4735-90bd-36c32a794633",
      "metadata": {
        "id": "fc79978c-aca2-4735-90bd-36c32a794633"
      },
      "outputs": [],
      "source": [
        "utils.plot_decision_boundary(boosted_clf, Xsp_train, ysp_train, Xsp_test, ysp_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb983471-5b2a-4e82-996e-fd4d0dd48d73",
      "metadata": {
        "id": "fb983471-5b2a-4e82-996e-fd4d0dd48d73"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "np.random.seed(300)\n",
        "# AdaBoost with subsampling\n",
        "boosted_clf = AdaBoost(DecisionTreeClassifier, n_learners=100, sample_size=1000, max_depth=1)\n",
        "boosted_clf.fit(Xsp_train, ysp_train)\n",
        "\n",
        "ysp_train_predict = boosted_clf.predict(Xsp_train)\n",
        "train_err = utils.empirical_err(ysp_train, ysp_train_predict)\n",
        "\n",
        "print(f'Train error: {train_err*100:0.2f}%')\n",
        "\n",
        "ysp_test_predict = boosted_clf.predict(Xsp_test)\n",
        "test_err = utils.empirical_err(ysp_test, ysp_test_predict)\n",
        "\n",
        "print(f'Test error: {test_err*100:0.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd20b32a-0e25-459e-af59-c648d339de37",
      "metadata": {
        "id": "bd20b32a-0e25-459e-af59-c648d339de37"
      },
      "outputs": [],
      "source": [
        "utils.plot_decision_boundary(boosted_clf, Xsp_train, ysp_train, Xsp_test, ysp_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f80cb61",
      "metadata": {
        "id": "7f80cb61"
      },
      "source": [
        "## Viola Jones and Boosting\n",
        "In this part, let us build a classifier based on the Viola-Jones framework for determining whether or not a picture has a face in it.\n",
        "\n",
        "Objectives for this section are:\n",
        "* understanding the feature extraction and weak classifier training procedures.\n",
        "* training a strong classifier using Boosting.\n",
        "* investigating the strong classifier using Boosting\n",
        "\n",
        "For data, we need both positive examples (examples with faces) and negative examples (examples without faces). For the positive samples, we use the training set of [Faces in the Wild](http://vis-www.cs.umass.edu/lfw/). This is a collection of images of celebrities matched with their names for use in tasks like face identification. The negative samples arise from the dog class from [Common Objects in Context](https://cocodataset.org/) (COCO). Let us first explore the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-xXZat1uOQ1k",
      "metadata": {
        "id": "-xXZat1uOQ1k"
      },
      "outputs": [],
      "source": [
        "!mkdir $PWD/data\n",
        "!wget -O $PWD/data/faces_selected.zip https://www.dropbox.com/scl/fi/tva9f41smurhha736oq4u/faces_selected.zip?rlkey=wnj1h2l6v1i7usdj55f94wamg&dl=1\n",
        "!wget -O $PWD/data/not_faces_selected.zip https://www.dropbox.com/scl/fi/q4uvxgu0ueoelsopejfwt/not_faces_selected.zip?rlkey=oobrbc7vbcmytb3oxhxsp4w1p&dl=1\n",
        "!unzip -q $PWD/data/faces_selected.zip -d $PWD/data/\n",
        "!unzip -q $PWD/data/not_faces_selected.zip -d $PWD/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RPj10ripUQkq",
      "metadata": {
        "id": "RPj10ripUQkq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List, Tuple, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MblBfEpJT37V",
      "metadata": {
        "id": "MblBfEpJT37V"
      },
      "outputs": [],
      "source": [
        "def create_split(X: List[List[float]], y: List[Any], split_ratio: float, random_state: int = None) -> Tuple[List[List[float]], List[Any], List[List[float]], List[Any]]:\n",
        "    '''\n",
        "    Randomly splits (X, y) into sets (X1, y1, X2, y2) such that\n",
        "    (X1, y1) contains split_ratio fraction of the data. The rest goes into (X2, y2).\n",
        "\n",
        "    Args:\n",
        "        X: Data features as a list of lists (size: m x d)\n",
        "        y: Data labels as a list (size: m)\n",
        "        split_ratio: Fraction of data to keep in (X1, y1) (must be between 0 and 1)\n",
        "        random_state: Random seed for reproducibility (default: None)\n",
        "\n",
        "    Returns:\n",
        "        (X1, y1, X2, y2): Each is a Python list.\n",
        "    '''\n",
        "    assert 0.0 <= split_ratio <= 1.0, \"split_ratio must be between 0 and 1\"\n",
        "    assert len(X) == len(y), \"Mismatch between number of samples in X and y\"\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    if random_state is not None:\n",
        "        random.seed(random_state)\n",
        "\n",
        "    # Shuffle indices\n",
        "    data = list(zip(X, y))  # Pair features with labels\n",
        "    random.shuffle(data)  # Shuffle in-place\n",
        "    X_shuffled, y_shuffled = zip(*data)  # Unzip back\n",
        "\n",
        "    # Convert to lists (since zip() returns tuples)\n",
        "    X_shuffled, y_shuffled = list(X_shuffled), list(y_shuffled)\n",
        "\n",
        "    # Compute split index\n",
        "    m1 = int(split_ratio * len(X))\n",
        "\n",
        "    # Split data\n",
        "    X1, y1 = X_shuffled[:m1], y_shuffled[:m1]\n",
        "    X2, y2 = X_shuffled[m1:], y_shuffled[m1:]\n",
        "\n",
        "    return X1, y1, X2, y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6234d7f0",
      "metadata": {
        "id": "6234d7f0"
      },
      "outputs": [],
      "source": [
        "XVJ, yVJ = utils.load_raw_vj_data(cap_class=1000)\n",
        "train_test_ratio = 0.8\n",
        "X_train, y_train, X_test, y_test = create_split(XVJ, yVJ, train_test_ratio)\n",
        "positive_samples = [X_train[i] for i in range(len(y_train)) if y_train[i]==1]\n",
        "negative_samples = [X_train[i] for i in range(len(y_train)) if y_train[i]==-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963cd1da",
      "metadata": {
        "id": "963cd1da"
      },
      "outputs": [],
      "source": [
        "utils.plot_data_grid(positive_samples, negative_samples, title_string=\"training images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4838e2e5",
      "metadata": {
        "id": "4838e2e5"
      },
      "source": [
        "In order to use the Viola-Jones face detector, we will rescale the images and convert them to greyscale. For this, we provide a preprocessing functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2380b9",
      "metadata": {
        "id": "2b2380b9"
      },
      "outputs": [],
      "source": [
        "def greyscale_and_resize(images, img_dim=64):\n",
        "    output_images = []\n",
        "    for img in images:\n",
        "        if len(img.shape)>2:\n",
        "            grey_scale_img = np.mean(img, axis=2)\n",
        "        else:\n",
        "            grey_scale_img = img\n",
        "        same_size_img = transform.resize(grey_scale_img, (img_dim, img_dim))\n",
        "        output_images.append(same_size_img)\n",
        "    return np.array(output_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B52Z7Ohv96IS",
      "metadata": {
        "id": "B52Z7Ohv96IS"
      },
      "outputs": [],
      "source": [
        "def preprocess_images(images, img_dim=64, normalize=True):\n",
        "    output_images = []\n",
        "    for img in images:\n",
        "        # Convert to grayscale if not already\n",
        "        if len(img.shape) > 2:\n",
        "            grey_scale_img = np.mean(img, axis=2)\n",
        "        else:\n",
        "            grey_scale_img = img\n",
        "\n",
        "        # Resize to the target dimension\n",
        "        resized_img = transform.resize(grey_scale_img, (img_dim, img_dim), anti_aliasing=True)\n",
        "\n",
        "        # Normalize\n",
        "        if normalize:\n",
        "            resized_img = (resized_img - np.min(resized_img)) / (np.max(resized_img) - np.min(resized_img) + 1e-8)  # Avoid division by zero\n",
        "\n",
        "        output_images.append(resized_img)\n",
        "\n",
        "    return np.array(output_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67dbab30",
      "metadata": {
        "id": "67dbab30"
      },
      "source": [
        "Recall, the four feature templates considered in the Viola-Jones detector are the following, where the black bands are \"positive\" and the white bands \"negative.\" Applying the feature involves computing the sum of the pixels in the black bands and then subtracting from that the sum of the pixels in the white bands.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1QmjdWDZU3UJl1yS5xGxl8KhUXzbVDhKY\">\n",
        "<p> Image from: https://www.mygreatlearning.com/blog/viola-jones-algorithm/ </p>\n",
        "\n",
        "To generate these, we will use the following helper classes, inspired by the ones in [this repository](https://github.com/salvacarrion/viola-jones)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca608a7",
      "metadata": {
        "id": "fca608a7"
      },
      "outputs": [],
      "source": [
        "# These classes adapted from https://github.com/salvacarrion/viola-jones\n",
        "class Rectangle:\n",
        "    def __init__(self, x, y, w, h):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.w = w\n",
        "        self.h = h\n",
        "\n",
        "    def compute_area(self, integral_img):\n",
        "        '''\n",
        "        integral_img is (n, dim, dim)\n",
        "        '''\n",
        "        a = (self.x-1, self.y-1)\n",
        "        b = (self.x+self.w-1, self.y)\n",
        "        c = (self.x, self.y+self.h-1)\n",
        "        d = (self.x + self.w-1, self.y+self.h-1)\n",
        "        n, sh1, sh2 = integral_img.shape\n",
        "        if b[0] > sh2 or d[1] > sh1:\n",
        "            print(\"Index Out of Bounds\")\n",
        "            return None\n",
        "        return integral_img[:,d[1], d[0]] - integral_img[:,b[1], b[0]] - integral_img[:,c[1], c[0]] + integral_img[:,a[1], a[0]]\n",
        "\n",
        "class HaarFeature:\n",
        "    def __init__(self, pos, neg):\n",
        "        self.positives = pos\n",
        "        self.negatives = neg\n",
        "\n",
        "    def compute_value(self, integral_img):\n",
        "        positive_amt = np.sum(np.array([r.compute_area(integral_img) for r in self.positives]), axis=0)\n",
        "        negative_amt = np.sum(np.array([r.compute_area(integral_img) for r in self.negatives]), axis=0)\n",
        "        return positive_amt - negative_amt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9037db38",
      "metadata": {
        "id": "9037db38"
      },
      "source": [
        "We wish to apply these features at varying scales and locations within the image. Naively, computing the sum of the pixels in these regions might take up to $O(d^2)$ time, where $d$ is the dimension of the (square) image. One major innovation of the original paper was the idea of _integral images_ which allowed for computation of these features in constant time per feature.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1fnuDgZqkMjUpTboXhaRU7IaGyUMpYdrJ\">\n",
        "<p>  Image from: https://towardsdatascience.com/the-intuition-behind-facial-detection-the-viola-jones-algorithm-29d9106b6999\" </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef584d7a",
      "metadata": {
        "id": "ef584d7a"
      },
      "outputs": [],
      "source": [
        "def compute_integral_img(imgs):\n",
        "    '''\n",
        "    imgs is of shape (n, d_1, d_2)\n",
        "    '''\n",
        "    n, d_1, d_2 = imgs.shape\n",
        "    integral_imgs = np.zeros((n, d_1, d_2))\n",
        "    for i in range(d_1):\n",
        "        integral_imgs[:, i, 0] = np.sum(imgs[:, :i+1, 0], axis = 1)\n",
        "    for j in range(d_2):\n",
        "        integral_imgs[:, 0, j] = np.sum(imgs[:, 0, :j+1], axis = 1)\n",
        "    for i in range(1,d_1):\n",
        "        for j in range(1,d_2):\n",
        "            integral_imgs[:, i, j] = imgs[:, i, j] + integral_imgs[:, i, j-1] + integral_imgs[:, i-1, j] - integral_imgs[:, i-1, j-1]\n",
        "    return integral_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "962734ba",
      "metadata": {
        "id": "962734ba"
      },
      "outputs": [],
      "source": [
        "## apply preprocessing steps\n",
        "phi_X = compute_integral_img(preprocess_images(X_train, img_dim=24,normalize=True))\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1260c871",
      "metadata": {
        "id": "1260c871"
      },
      "source": [
        "Next, we must compute the features from the template features described above. Below, we provide a function to compute the features across the whole image. Note that this function has optional parameters `stride` and `scale_stride` that limit the set of features we compute. `stride` refers to horizontal translation, and `scale_stride` refers to the difference between successive scalings.\n",
        "\n",
        "This function does not `return` anything -- it only `yields`. Why is that? The object this contructs is called a [generator](https://wiki.python.org/moin/Generators). Generators allow us to build an iterator without explicitly instantiating all of it, thereby taking up memory. Here, we use a generator so that we can process each feature progressively but do not need to store them all in memory at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c4cdbf",
      "metadata": {
        "id": "43c4cdbf"
      },
      "outputs": [],
      "source": [
        "def feature_generator(img_dim, base_size=(5,5), scale_stride=1, stride=1):\n",
        "    scales = np.arange(1, img_dim//min(base_size), scale_stride)\n",
        "    for x_s in scales:\n",
        "        for y_s in scales:\n",
        "            start_pts_x = np.arange(0, img_dim, stride, dtype=int)\n",
        "            start_pts_y = np.arange(0, img_dim, stride, dtype=int)\n",
        "            for x in start_pts_x:\n",
        "                for y in start_pts_y:\n",
        "                    features_to_yield = []\n",
        "                    w = x_s * base_size[1]\n",
        "                    h = y_s * base_size[0]\n",
        "                    if x + 2*w > img_dim or y + 2*h > img_dim:\n",
        "                        break\n",
        "                    else:\n",
        "                        r1 = Rectangle(x, y, w, h)\n",
        "                        r2 = Rectangle(x+w, y, w, h)\n",
        "                        features_to_yield.append(HaarFeature([r2], [r1]))\n",
        "\n",
        "                        r3 = Rectangle(x, y+h, w, h)\n",
        "                        features_to_yield.append(HaarFeature([r3], [r1]))\n",
        "\n",
        "                        r4 = Rectangle(x+w, y+h, w, h)\n",
        "                        features_to_yield.append(HaarFeature([r2, r3], [r1, r4]))\n",
        "\n",
        "                    if x+3*w > img_dim:\n",
        "                        break\n",
        "                    else:\n",
        "                        r1 = Rectangle(x, y, w, h)\n",
        "                        r2 = Rectangle(x+w, y, w, h)\n",
        "                        r5 = Rectangle(x+2*w, y, w, h)\n",
        "\n",
        "                        features_to_yield.append(HaarFeature([r2], [r1, r5]))\n",
        "                    yield features_to_yield"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d1bcda4",
      "metadata": {
        "id": "7d1bcda4"
      },
      "source": [
        "With all these necessary pieces implemented, let us finally implement the Viola-Jones weak classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea96ea99",
      "metadata": {
        "id": "ea96ea99"
      },
      "outputs": [],
      "source": [
        "class V_J_weak:\n",
        "    def __init__(self, X, y, ft_stride=5, scale_stride=10):\n",
        "        '''\n",
        "        X is the set integral images\n",
        "        '''\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.feature = None\n",
        "        self.T = 0\n",
        "        self.stride = ft_stride\n",
        "        self.scale_stride = scale_stride\n",
        "        self.score = 0\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        n, img_dim, _ = X.shape\n",
        "        feature_gen = feature_generator(img_dim, scale_stride=self.scale_stride, stride=self.stride)\n",
        "        max_score = -np.inf\n",
        "        best_feature = None\n",
        "        if sample_weight is None:\n",
        "            sample_weight = 1/n*np.ones(n)\n",
        "        i = 0\n",
        "        while True:\n",
        "            i = i+1\n",
        "            try:\n",
        "                item = next(feature_gen)\n",
        "            except:\n",
        "                break\n",
        "            for f in item:\n",
        "                features = f.compute_value(X)\n",
        "                pos_ft, pos_wt = features[y==1], sample_weight[y==1]\n",
        "                neg_ft, neg_wt = features[y==-1], sample_weight[y==-1]\n",
        "                T, s = find_and_score_threshold(pos_ft, neg_ft, pos_wt, neg_wt)\n",
        "                if s > max_score:\n",
        "                    max_score = s\n",
        "                    best_feature = (f, T)\n",
        "        self.feature, self.T = best_feature\n",
        "        self.score = max_score\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return 2*(self.feature.compute_value(X) > self.T) - 1\n",
        "\n",
        "\n",
        "def find_and_score_threshold(class_1, class_2, wt_pos, wt_neg):\n",
        "    min_pt = min(min(class_1), min(class_2))\n",
        "    max_pt = max(max(class_1), max(class_2))\n",
        "    score = lambda T: (np.sum(np.multiply((class_1 > T), wt_pos)) + np.sum(np.multiply((class_2 < T),wt_neg)))/(np.sum(wt_pos) + np.sum(wt_neg))\n",
        "    potential_ts = np.linspace(min_pt, max_pt, 1000)\n",
        "    scored_ts = [score(t) for t in potential_ts]\n",
        "    i = np.argmax(scored_ts)\n",
        "    return potential_ts[i], scored_ts[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "542cdb1d",
      "metadata": {
        "id": "542cdb1d"
      },
      "source": [
        "### [Task 2] Run Boosting on Viola-Jones Weak Classifiers\n",
        "Equipped with all the code, run AdaBoost on Viola Jones weak classifiers. Try messing with strides and n_learners to get what you think is a \"good\" classifier. Do test the case both `stride = 1` and `scale_stride = 1`, and compare performance to larger values.\n",
        "\n",
        "**Check yourself**: what are the largest values you can set these two parameters to? What are the largest sensible values you can set these parameters to?\n",
        "\n",
        "Also, the `n_learners` in AdaBoost is really a hyperparameter, and you may consider tuning it. Remember to use everything things you know about validation and test sets!\n",
        "\n",
        "Another important thing to consider is `img_dim` when you created `phi_X` which is the resolution of the original image you would work with. The higher resolution will achieve a better performance, however, it may be computationally expensive. Something like `img_dim=24` runs in under 15 mins, and gives a decent accuracy. But you may also explore increasing this further.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4142773",
      "metadata": {
        "id": "e4142773"
      },
      "outputs": [],
      "source": [
        "# TASK 2 CODE\n",
        "# TASK 2 CODE\n",
        "\n",
        "print(f'Train error: {vj_train_err*100:0.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b57f22",
      "metadata": {
        "id": "64b57f22"
      },
      "outputs": [],
      "source": [
        "test_phi_X = compute_integral_img(preprocess_images(X_test, img_dim=24,normalize=True))\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daabbf3e",
      "metadata": {
        "id": "daabbf3e"
      },
      "outputs": [],
      "source": [
        "yvj_test_predict = boosted_clf_vj.predict(test_phi_X)\n",
        "vj_test_err = utils.empirical_err(y_test, yvj_test_predict)\n",
        "\n",
        "print(f'Test error: {vj_test_err*100:0.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e654009",
      "metadata": {
        "id": "2e654009"
      },
      "source": [
        "### Investigate Boosted Predictor and its Constitutent Weak Predictors\n",
        "\n",
        "To understand what is happening inside the Viola-Jones classifier using Boosting, let us examine the outputs of various weak classifiers at increasing \"depths\" and of the final boosted classifier to see where the respective classifiers fail.\n",
        "\n",
        "To this end, we present two functions. The first extracts the indices on which a particular classifier succeeds and fails and use that to return the four different categories of images: faces where it failed, non-faces where it failed, faces where it succeeded, and non-faces where it suceeded. The other visualizes a subset of the images extracted in a grid for ease of inspection. **Be sure to visualize both the raw images and the `greyscale_and_resized` images -- that is, replace the third argument with the appropriate input.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a24c398",
      "metadata": {
        "id": "6a24c398"
      },
      "outputs": [],
      "source": [
        "def extract_rights_wrongs(boosted_clf, processed_X_test, X_test, y_test, idx=None):\n",
        "    '''\n",
        "    could either have this fn only handle the weak classifiers, or just write\n",
        "    one fn with idx as an optional arg, and if it is not received, it will just run clf.predict\n",
        "\n",
        "    takes in processed Xs for inference but also raw Xs to output\n",
        "    '''\n",
        "    if idx is not None:\n",
        "        clf = boosted_clf.learned_clfs[idx]\n",
        "    else:\n",
        "        clf = boosted_clf\n",
        "    pred = clf.predict(processed_X_test)\n",
        "    wrong_idxs = np.where(np.not_equal(pred, y_test))[0]\n",
        "    right_idxs = np.where(np.equal(pred, y_test))[0]\n",
        "    class_1_incorrect = [X_test[i] for i in wrong_idxs if y_test[i]==1]\n",
        "    class_0_incorrect = [X_test[i] for i in wrong_idxs if y_test[i]==-1]\n",
        "    class_1_correct = [X_test[i] for i in right_idxs if y_test[i]==1]\n",
        "    class_0_correct = [X_test[i] for i in right_idxs if y_test[i]==-1]\n",
        "    return class_1_incorrect, class_0_incorrect, class_1_correct, class_0_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c286e18",
      "metadata": {
        "id": "4c286e18"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_grid(wrong_faces, wrong_notfaces, right_faces, right_notfaces, title_string):\n",
        "    f, axarr = plt.subplots(5,7, figsize=(14,10))#, gridspec_kw={'hspace': 0.1})\n",
        "    f.tight_layout()\n",
        "    for i in range(5):\n",
        "        for j in range(7):\n",
        "            try:\n",
        "                if j < 3:\n",
        "                    if i < 2:\n",
        "                        axarr[i,j].imshow(wrong_faces[i*3 + j])# , aspect = \"auto\")\n",
        "                    if i > 2:\n",
        "                        axarr[i, j].imshow(wrong_notfaces[(i-3)*3 + j])\n",
        "                elif j == 3:\n",
        "                    axarr[i,j].imshow(np.ones((2,2,3)))# , aspect = \"auto\")\n",
        "                elif j > 3:\n",
        "                    if i < 2:\n",
        "                        axarr[i,j].imshow(right_faces[i*3 + j-4])\n",
        "                    if i > 2:\n",
        "                        axarr[i,j].imshow(right_notfaces[(i-3)*3 + j - 4])\n",
        "            except:\n",
        "                axarr[i,j].imshow(np.ones((2,2,3)))\n",
        "            axarr[i,j].axis('off')\n",
        "    f.subplots_adjust(hspace=0.0, wspace=0.0)#, right=0.7)\n",
        "\n",
        "    f.suptitle(title_string, y=1.02, size=20)\n",
        "    axarr[0,1].set_title(\"GOT WRONG\", size=16)\n",
        "    axarr[0,5].set_title(\"GOT RIGHT\", size=16)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdece0cc",
      "metadata": {
        "id": "fdece0cc"
      },
      "outputs": [],
      "source": [
        "plot_confusion_grid(*extract_rights_wrongs(boosted_clf_vj, test_phi_X, X_test, y_test, idx=0), \"first weak clf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f20e5b5",
      "metadata": {
        "id": "2f20e5b5"
      },
      "outputs": [],
      "source": [
        "plot_confusion_grid(*extract_rights_wrongs(boosted_clf_vj, test_phi_X, X_test, y_test), \"final boosted clf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2da5c0d",
      "metadata": {
        "id": "b2da5c0d"
      },
      "source": [
        "<span style=\"color: red\">\n",
        "<h4 style=\"font-weight: bold\">[Answer Question 1]</h4>\n",
        "\n",
        "* For some of the weak classifiers, visualize some images on which it is quite discriminative and others on which it is not. Do you notice any trends?\n",
        "\n",
        "* What examples does the final boosted classifier succeed and fail on?\n",
        "\n",
        "Address these questions in 2-3 bullet points.\n",
        "\n",
        "<h4 style=\"font-weight: bold\">---------------------</h4>\n",
        "\n",
        "<span style=\"color: blue\">\n",
        "Answer:\n",
        "</span>\n",
        "\n",
        "<h4 style=\"font-weight: bold\">---------------------</h4>\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb88f66",
      "metadata": {
        "id": "ffb88f66"
      },
      "source": [
        "<span style=\"color: red\">\n",
        "<h4 style=\"font-weight: bold\">[Answer Question 2]</h4>\n",
        "\n",
        "Finally, now that you've explored the model quite a bit, reflect on some limitations of this approach, both technically and practically. A couple of bullet points suffice.\n",
        "\n",
        "<h4 style=\"font-weight: bold\">---------------------</h4>\n",
        "\n",
        "<span style=\"color: blue\">\n",
        "Answer:\n",
        "</span>\n",
        "\n",
        "<h4 style=\"font-weight: bold\">---------------------</h4>\n",
        "</span>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}