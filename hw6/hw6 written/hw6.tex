\frenchspacing
\documentclass{amsart}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{bbm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{tikz}
\pagestyle{fancy}
\usepackage[margin=1in]{geometry}
\newgeometry{left=1.5cm, right=1.5cm, top = 1.5cm}
\fancyhfoffset[E,O]{0pt}
\allowdisplaybreaks\rhead{Andrew Lys}%% <-- your name here
\chead{Problem Set 6}
\cfoot{\thepage}
\lhead{\today}



%% your macros -->
\newcommand{\nn}{\mathbb{N}}    %% naturals
\newcommand{\zz}{\mathbb{Z}}    %%integers
\newcommand{\rr}{\mathbb{R}}    %% real numbers
\newcommand{\cc}{\mathbb{C}}    %% complex numbers
\newcommand{\ff}{\mathbb{F}}
\newcommand{\qq}{\mathbb{Q}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\limn}{\lim_{n \to\infty}} %%lim n to infty shorthand
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vu}{\mathbf{u}}
\DeclareMathOperator{\var}{Var}  %% variance
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\Cov}{Cov}
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{exercise}{Exercise}[section]


\begin{document}
\noindent
Problem Set 6   \hfill \today  %% <-- Update Notes here ***
\smallskip
\hrule
\smallskip
\noindent
Solutions by {\bf Andrew Lys} \qquad   %% <-- your name here ***
  {\tt andrewlys (at) u.e.}      %% <-- your uchicago email address here ***

\vspace{0.5cm}

\section{Gaussian Mixtures}
\section{Modeling Text Documents}
\subsection{A Simple Model}

\begin{enumerate}[(a)]
  \item 
    We shall denote $p_{\mathrm{topic}}$ as $p$, since it is given that this is a single probability. 
    Additionally, we denote 
    \[p_y[i] = P(x_i = 1|Y = y)\]
    Given a sample 
    \[
      S = \{(x_1,y_1), \ldots, (x_n, y_n)\}
    \]
    Some of the $x_i$'s repeat, so let ${\{(x_j, y_j)\}}_{j = 1}^k$ be the elements of the sample such that each $(x_i, y_i)$ occurs only once.
    Then let
    \[
      n_{y,j} = |\{i : (x_j, y_j) = (x_i, y_i) \in S\}|
    \]
    And similarly, we define
    \[n_y = |\{i : y_i = y, (x_i, y_i) \in S\}|\]
    Then, we should expect that our MLEs for $p$ and $\{p_y\}$ to be the sample errors, i.e. 
    \begin{align*}
      \hat{p} &= \frac{n_1}{n}\\
      \hat{p}_y[i] &= \frac{n_{y, i}}{n_y}
    \end{align*}
    We derive this with the MLEs estimators. 
    \[L(p, \{p_y\}|S) = P(S| p, \{p_y\})\]
    First, we prove that these samples are independent.
    \begin{align}
      P(x_j, y_j | x_i, y_i) &= P(x_j, y_j|x_i)\\
      &= P(x_j| y_j, x_i)P(y_j|x_i)\\
      &= P(x_j|y_j)P(y_j) = P(x_j, y_j)
    \end{align}
    $(1)$ is true because $y_j$ is chosen independently of $y_i$, and $x_j$ does not depend on $y_j$. 
	$(2)$ is true by the definition of conditional probability. 
	$(3)$ is true because $x_j | y_j$ is conditionally independent of $x_i$

\end{enumerate}
\end{document}
